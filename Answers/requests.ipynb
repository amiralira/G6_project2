{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "from jdatetime import datetime\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "import re\n",
    "file_dir = \"sales_data.csv\"\n",
    "file_dir2 = \"dollar_price.csv\"\n",
    "file_dir3 = \"country-cities-data.csv\"\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# li = df[\"Order_Date\"].str.split(\"-\").str[0]\n",
    "# li.unique()\n",
    "\n",
    "# test = df[df[\"Model_Name\"] == \"Vostro 3568\"]\n",
    "# test = test[\n",
    "#     [\n",
    "#         # \"Manufacturer\",\n",
    "#         \"Model_Name\",\n",
    "#         # \"Category\",\n",
    "#         \"Screen_Size\",\n",
    "#         \"Screen\",\n",
    "#         \"CPU\",\n",
    "#         \"GPU\",\n",
    "#         # \"RAM\",\n",
    "#         \"Storage\",\n",
    "#         # \"OS\",\n",
    "#         # \"OS_Version\",\n",
    "#         \"Weight\",\n",
    "#     ]\n",
    "# ]\n",
    "# test = test.drop_duplicates()\n",
    "\n",
    "# df_products[df_products[\"Model_Name\"] == \"Vostro 3568\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sales_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(file_dir, low_memory\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      2\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mScreen_Size\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mScreen_Size\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n\u001b[1;32m      3\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mRAM\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mRAM\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mGB\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sales_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_dir, low_memory=False)\n",
    "df[\"Screen_Size\"] = df[\"Screen_Size\"].str.replace('\"', \"\").astype(float)\n",
    "df[\"RAM\"] = df[\"RAM\"].str.replace(\"GB\", \"\").astype(int)\n",
    "df[\"Weight\"] = df[\"Weight\"].replace([\"kgs\", \"kg\"], \"\", regex=True).astype(float)\n",
    "\n",
    "df[\"Date_Shamsi\"] = df[\"Order_Date\"].copy()\n",
    "df[\"Order_Date\"] = df[\"Order_Date\"].apply(\n",
    "    lambda x: datetime.strptime(x, \"%Y-%m-%d\").togregorian()\n",
    ")\n",
    "\n",
    "df_dollar_price = pd.read_csv(file_dir2, index_col=[0])\n",
    "df_dollar_price[\"miladi\"] = pd.to_datetime(df_dollar_price[\"miladi\"])\n",
    "\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    df_dollar_price,\n",
    "    how=\"left\",\n",
    "    left_on=\"Order_Date\",\n",
    "    right_on=\"miladi\",\n",
    ")\n",
    "df.drop(columns=[\"miladi\", \"shamsi\"], inplace=True)\n",
    "df.rename(columns={\"close_price\": \"Dollar_Price\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.copy()\n",
    "df_temp[\"Total_Price\"] = df_temp[\"Total_Price\"] / df_temp[\"Dollar_Price\"]\n",
    "df_temp[\"Profit\"] = df_temp[\"Profit\"] / df_temp[\"Dollar_Price\"]\n",
    "\n",
    "sales_by_city = df_temp.groupby(\"Branch\")[\"Total_Price\"].sum()\n",
    "\n",
    "profit_by_city = df_temp.groupby(\"Branch\")[\"Profit\"].mean()\n",
    "\n",
    "# محاسبه نسبت تخفیف به تعداد فروخته‌شده بر اساس شهر\n",
    "discount_to_sales_ratio = df_temp.groupby(\"Branch\").apply(\n",
    "    lambda x: x[\"Discount\"].sum() / x[\"Quantity\"].sum()\n",
    ")\n",
    "\n",
    "# محاسبه نسبت قیمت به سود بر اساس شهر\n",
    "price_to_profit_ratio = df_temp.groupby(\"Branch\").apply(\n",
    "    lambda x: x[\"Total_Price\"].sum() / x[\"Profit\"].sum()\n",
    ")\n",
    "\n",
    "# محاسبه نسبت سفارشات فوری بر اساس شهر\n",
    "priority_orders_ratio = (\n",
    "    df_temp[df_temp[\"Order_Priority\"] == \"H\"]\n",
    "    .groupby(\"Branch\")[\"Order_Priority\"]\n",
    "    .count()\n",
    "    / df_temp.groupby(\"Branch\")[\"Order_Priority\"].count()\n",
    ")\n",
    "\n",
    "city_metrics = pd.DataFrame(\n",
    "    {\n",
    "        \"Sales\": sales_by_city,\n",
    "        \"Discount_to_Sales_Ratio\": discount_to_sales_ratio,\n",
    "        \"Price_to_Profit_Ratio\": price_to_profit_ratio,\n",
    "        \"Priority_Orders_Ratio\": priority_orders_ratio,\n",
    "        \"Profitability\": profit_by_city,\n",
    "    }\n",
    ")\n",
    "\n",
    "city_metrics = city_metrics.sort_values(by=[\"Profitability\"], ascending=False)\n",
    "city_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pupulation = pd.read_csv(file_dir3)\n",
    "df_pupulation.loc[15, \"city\"] = \"Hamedan\"\n",
    "\n",
    "df_branchs = pd.DataFrame(columns=[\"Branch\", \"Sum_Sell\", \"Total_Price\", \"Profit\"])\n",
    "df_temp = df.copy()\n",
    "\n",
    "df_temp[\"Total_Price\"] = df_temp[\"Total_Price\"] / df_temp[\"Dollar_Price\"]\n",
    "df_temp[\"Profit\"] = df_temp[\"Profit\"] / df_temp[\"Dollar_Price\"]\n",
    "\n",
    "for branch in df_temp[\"Branch\"].unique():\n",
    "    temp = df_temp[df_temp[\"Branch\"] == branch]\n",
    "    df_branchs.loc[len(df_branchs.index) + 1] = {\n",
    "        \"Branch\": branch,\n",
    "        # \"Sum_Sell\": len(temp),\n",
    "        \"Sum_Sell\": temp[\"Quantity\"].sum(),\n",
    "        \"Total_Price\": temp[\"Total_Price\"].sum().round(2),\n",
    "        \"Profit\": temp[\"Profit\"].sum().round(2),\n",
    "    }\n",
    "\n",
    "df_branchs[\"Profit_key\"] = df_branchs[\"Profit\"] / df_branchs[\"Total_Price\"]\n",
    "\n",
    "df_branchs = pd.merge(\n",
    "    df_branchs,\n",
    "    df_pupulation,\n",
    "    how=\"left\",\n",
    "    left_on=\"Branch\",\n",
    "    right_on=\"city\",\n",
    ")\n",
    "df_branchs = df_branchs.drop(columns=[\"city\", \"country\", \"latitude\", \"longitude\"])\n",
    "\n",
    "weight_profit = 0.4\n",
    "weight_margin = 0.3\n",
    "weight_sales = 0.2\n",
    "weight_population = 0.1\n",
    "\n",
    "df_branchs[\"Weighted_Score\"] = (\n",
    "    df_branchs[\"Profit\"] * weight_profit\n",
    "    + df_branchs[\"Profit_key\"] * weight_margin\n",
    "    + df_branchs[\"Sum_Sell\"] * weight_sales\n",
    "    + df_branchs[\"pop2023\"] * weight_population\n",
    ")\n",
    "\n",
    "df_branchs = df_branchs.sort_values(by=[\"Weighted_Score\"], ascending=False)\n",
    "df_branchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.copy()\n",
    "df_temp[\"Total_Price\"] = df_temp[\"Total_Price\"] / df_temp[\"Dollar_Price\"]\n",
    "\n",
    "df_with_discount = df_temp[df_temp[\"Discount\"] > 0][\"Total_Price\"]  # ['Quantity']\n",
    "df_without_discount = df_temp[df_temp[\"Discount\"] == 0][\"Total_Price\"]  # ['Quantity']\n",
    "\n",
    "t_stat, p_value = ttest_ind(df_with_discount, df_without_discount, equal_var=False)\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"تخفیف بر میزان فروش تأثیر دارد\")\n",
    "else:\n",
    "    print(\"تخفیف بر میزان فروش تأثیر ندارد\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Grouper(key=\"Order_Date\", freq=\"Y\")\n",
    "df_temp = df[df[\"Discount\"] != 0].copy()\n",
    "df_temp[\"Discount\"] = df_temp[\"Discount\"] * df_temp[\"Quantity\"]\n",
    "result = (\n",
    "    df_temp.groupby(df_temp[\"Order_Date\"].dt.year)\n",
    "    .agg({\"Discount\": \"mean\", \"Quantity\": \"sum\"})\n",
    "    .reset_index()\n",
    ")\n",
    "result = result.sort_values(by=[\"Quantity\"], ascending=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.copy()\n",
    "df_temp[\"Profit\"] = df_temp[\"Profit\"] / df_temp[\"Dollar_Price\"]\n",
    "\n",
    "X = sm.add_constant(df_temp[\"Discount\"])\n",
    "y = df_temp[\"Profit\"]\n",
    "model = sm.OLS(y, X).fit()\n",
    "# print(model.summary())\n",
    "\n",
    "print(\"Degrees of Freedom: \", model.df_resid)\n",
    "print(\"t_stat: \", model.tvalues[\"Discount\"])\n",
    "print(\"p-value: \", model.pvalues[\"Discount\"])\n",
    "\n",
    "alpha = 0.05\n",
    "if model.pvalues[\"Discount\"] < alpha:\n",
    "    print(\"تخفیف بر میزان سود تأثیر دارد\")\n",
    "else:\n",
    "    print(\"تخفیف بر میزان سود تأثیر ندارد\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_temp = df[df[\"Discount\"] != 0].copy()\n",
    "df_temp[\"Discount\"] = df_temp[\"Discount\"] * df_temp[\"Quantity\"]\n",
    "result = (\n",
    "    df_temp.groupby(df_temp[\"Order_Date\"].dt.year)\n",
    "    .agg({\"Discount\": \"mean\"})\n",
    "    .reset_index()\n",
    ")\n",
    "df_temp = df.copy()\n",
    "df_temp[\"Profit\"] = (df_temp[\"Profit\"] / df_temp[\"Dollar_Price\"]).round(2)\n",
    "result2 = (\n",
    "    df_temp.groupby(df_temp[\"Order_Date\"].dt.year).agg({\"Profit\": \"sum\"}).reset_index()\n",
    ")\n",
    "df_temp = pd.merge(\n",
    "    result,\n",
    "    result2,\n",
    "    how=\"left\",\n",
    "    left_on=\"Order_Date\",\n",
    "    right_on=\"Order_Date\",\n",
    ")\n",
    "df_temp = df_temp.sort_values(by=[\"Profit\"], ascending=False)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_temp = df.copy()\n",
    "# df_temp[\"Total_Price\"] = df_temp[\"Total_Price\"] / df_temp[\"Dollar_Price\"]\n",
    "df_temp[\"Profit\"] = df_temp[\"Profit\"] / df_temp[\"Dollar_Price\"]\n",
    "df_temp[\"Price\"] = df_temp[\"Price\"] / df_temp[\"Dollar_Price\"]\n",
    "\n",
    "brands = df_temp[\"Manufacturer\"].unique()\n",
    "categories = df_temp[\"Category\"].unique()\n",
    "capital_allocation = pd.DataFrame(index=brands, columns=categories)\n",
    "# model = LinearRegression()\n",
    "\n",
    "for brand in brands:\n",
    "    for category in categories:\n",
    "        filtered_data = df_temp[\n",
    "            (df_temp[\"Manufacturer\"] == brand) & (df_temp[\"Category\"] == category)\n",
    "        ]\n",
    "\n",
    "        features, target = 0, 0\n",
    "        if len(filtered_data) > 0:\n",
    "            # features = filtered_data[['Price']].values.reshape(-1, 1)\n",
    "            target = filtered_data[\"Profit\"].values\n",
    "\n",
    "        # model.fit(features, target)\n",
    "        # پیش‌بینی سود بر اساس قیمت\n",
    "        # predicted_profits = model.predict(features)\n",
    "        # تخصیص سرمایه بهینه بر اساس میانگین سود پیش‌بینی شده\n",
    "        optimal_capital = np.max(target)\n",
    "        capital_allocation.at[brand, category] = optimal_capital\n",
    "\n",
    "capital_allocation[\"sum_profits_per_manufacturer\"] = capital_allocation.sum(axis=1)\n",
    "capital_allocation.loc[\"sum_profits_per_category\"] = capital_allocation.sum(axis=0)\n",
    "capital_allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result_df = (\n",
    "    df.assign(Profit_Per_Dollar=(df[\"Profit\"] / df[\"Dollar_Price\"]).round(2))\n",
    "    .groupby(\"Manufacturer\")\n",
    "    .agg(Profit_Sum=(\"Profit_Per_Dollar\", \"sum\"))\n",
    "    .sort_values(by=[\"Profit_Sum\"], ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = (\n",
    "    df.assign(Profit_Per_Dollar=(df[\"Profit\"] / df[\"Dollar_Price\"]).round(2))\n",
    "    .groupby(\"Category\")\n",
    "    .agg(Profit_Sum=(\"Profit_Per_Dollar\", \"sum\"))\n",
    "    .sort_values(by=[\"Profit_Sum\"], ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_temp = df.copy()\n",
    "\n",
    "cpu_regex = r'(\\d+(\\.\\d+)?)GHz'\n",
    "storage_regex = r'(\\d+)(?=[GB|TB])'\n",
    "\n",
    "df_encoded = pd.get_dummies(df_temp, columns=['OS', 'CPU', 'GPU'], prefix=['OS', 'CPU', 'GPU'])\n",
    "df_encoded['Storage_Size'] = df_temp['Storage'].str.extract(storage_regex).astype(float)\n",
    "selected_columns = df_encoded.filter(regex='^CPU_|^GPU_|^OS_|^storage_', axis=1)\n",
    "selected_columns = selected_columns.loc[:, selected_columns.dtypes == bool]\n",
    "selected_columns = selected_columns.astype(int)\n",
    "target = df_temp[\"Price\"] / df_temp[\"Dollar_Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_columns, target, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"Model R-squared score:\", score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the following values to connect to the database\n",
    "user = \"root\"\n",
    "password = \"khb!1mes2@K-pAsS3#zorie$\"\n",
    "host = \"localhost\"\n",
    "port = 3306\n",
    "database = \"project2\"\n",
    "\n",
    "engine = create_engine(\n",
    "    url=\"mysql+pymysql://{0}:%s@{1}/{2}\".format(user, host, database)\n",
    "    % quote_plus(password)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    M.Name AS Manufacturer,\n",
    "    P.Name,\n",
    "    C.Name AS Category,\n",
    "    R.Size AS RAM,\n",
    "    S.Model AS Storage,\n",
    "    Sp.Weight,\n",
    "    CPU_M.Name AS CPU_Manufacturer,\n",
    "    CPU.Model AS CPU_Model,\n",
    "    CPU.Frequency AS CPU_Freq,\n",
    "    GPU_M.Name AS GPU_Manufacturer,\n",
    "    GPU.Model AS GPU_Model,\n",
    "    OS.Name AS OS_Name,\n",
    "    OS.Version AS OS_Version,\n",
    "    Sc.Size AS Screen_Size,\n",
    "    Sc.Resolution AS Screen_Resolution,\n",
    "    Sc.Type AS Screen_Type,\n",
    "#     Prc.Price,\n",
    "#     Prc.Dollar_Price,\n",
    "#     Prc.Price / Prc.Dollar_Price AS Real_Price,\n",
    "    AVG(Prc.Price / Prc.Dollar_Price) OVER (PARTITION BY P.ID) AS Average_Real_Price\n",
    "FROM\n",
    "    Prices Prc\n",
    "JOIN\n",
    "    Products P ON Prc.Product_ID = P.ID\n",
    "LEFT JOIN\n",
    "    Manufacturers M ON P.Manufacturer_ID = M.ID\n",
    "LEFT JOIN\n",
    "    Categories C ON P.Category_ID = C.ID\n",
    "LEFT JOIN\n",
    "    Specs Sp ON P.Spec_ID = Sp.ID\n",
    "LEFT JOIN\n",
    "    RAMs R ON Sp.RAM_ID = R.ID\n",
    "LEFT JOIN\n",
    "    Storages S ON Sp.Storage_ID = S.ID\n",
    "LEFT JOIN\n",
    "    CPUs CPU ON Sp.CPU_ID = CPU.ID\n",
    "LEFT JOIN\n",
    "    Manufacturers CPU_M ON CPU.Manufacturer_ID = CPU_M.ID\n",
    "LEFT JOIN\n",
    "    GPUs GPU ON Sp.GPU_ID = GPU.ID\n",
    "LEFT JOIN\n",
    "    Manufacturers GPU_M ON GPU.Manufacturer_ID = GPU_M.ID\n",
    "LEFT JOIN\n",
    "    OSs OS ON Sp.OS_ID = OS.ID\n",
    "LEFT JOIN\n",
    "    Screens Sc ON Sp.Screen_ID = Sc.ID\n",
    "group by P.ID;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    P.Discount,\n",
    "    P.Quantity,\n",
    "    O.Date AS Order_Date,\n",
    "    P.Profit,\n",
    "    P.Dollar_Price,\n",
    "    M.Name AS Manufacturer,\n",
    "    C.Name AS Category\n",
    "FROM\n",
    "    Orders O\n",
    "JOIN\n",
    "    Prices P ON O.Price_ID = P.ID\n",
    "JOIN\n",
    "    Products Pr ON P.Product_ID = Pr.ID\n",
    "JOIN\n",
    "    Manufacturers M ON Pr.Manufacturer_ID = M.ID\n",
    "JOIN\n",
    "    Categories C ON Pr.Category_ID = C.ID;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, engine)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
